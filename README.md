# ğŸ§  PCA & Machine Learning sur donnÃ©es catÃ©gorielles

Ce projet explore deux approches de Machine Learning non supervisÃ©e et supervisÃ©e Ã  partir dâ€™un jeu de donnÃ©es contenant une variable cible catÃ©gorielle (`target`).

---

## ğŸ“ Fichiers fournis

- `Train.csv` : donnÃ©es d'entraÃ®nement avec variables explicatives et la colonne `target`.
- `Test.csv` : donnÃ©es de test Ã  exploiter ensuite.
- `Projet_3.ipynb` : notebook principal contenant toutes les Ã©tapes du projet.
- `README.md` : ce fichier.

---

## ğŸ¯ Objectif du projet

1. **RÃ©duction de dimension avec PCA**
2. **Clustering non supervisÃ©** (KMeans, DBSCAN, AgglomÃ©ratif, GMM)
3. **Ã‰valuation du clustering via Adjusted Rand Index (ARI)**
4. **Classification supervisÃ©e** (RandomForest, SVM, KNNâ€¦)
5. **Comparaison des performances des modÃ¨les supervisÃ©s**
6. **Visualisation** des rÃ©sultats

---

## ğŸ› ï¸ Technologies utilisÃ©es

- Python 3.9+
- Scikit-learn
- Pandas / Numpy
- Seaborn / Matplotlib
- Jupyter Notebook

---

## ğŸ”„ Pipeline gÃ©nÃ©ral

### 1. PrÃ©traitement
- Standardisation des donnÃ©es (`StandardScaler`)
- Encodage de la variable `target` si elle est catÃ©gorielle (`LabelEncoder`)

### 2. PCA
- RÃ©duction des dimensions pour expliquer 90â€¯% de la variance

### 3. Clustering non supervisÃ©
- KMeans
- DBSCAN
- Agglomerative Clustering
- Gaussian Mixture Models (GMM)
- Ã‰valuation via `Adjusted Rand Index (ARI)`

### 4. Classification supervisÃ©e
- SÃ©paration train/test (80/20)
- ModÃ¨les testÃ©s :
  - Random Forest
  - SVM
  - KNN
  - Logistic Regression
- Ã‰valuation :
  - Accuracy
  - Matrice de confusion
  - Classification report

---

## ğŸ“Š RÃ©sultats

### ğŸ§© Clustering

| ModÃ¨le       | ARI obtenu |
|--------------|------------|
| KMeans       | 0.071      |
| DBSCAN       | 0.015      |
| AgglomÃ©ratif | 0.041      |
| GMM          | 0.063      |

ğŸ‘‰ Aucun clustering ne reproduit bien la structure des vraies classes.

### ğŸ§  Classification

> Ã€ complÃ©ter avec les scores de prÃ©cision obtenus dans le notebook une fois l'exÃ©cution terminÃ©e.

---

## ğŸ“Œ Conclusion

- Le jeu de donnÃ©es ne prÃ©sente **pas de structure de clustering claire**.
- Lâ€™approche **supervisÃ©e** donne des rÃ©sultats bien **plus pertinents** pour prÃ©dire la `target`.
- Le PCA permet une **rÃ©duction efficace** de la dimension sans perte majeure d'information.

---

## ğŸš€ Ã€ venir

- Visualisation avec t-SNE ou UMAP
- Export des modÃ¨les pour production